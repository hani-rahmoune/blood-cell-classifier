# -*- coding: utf-8 -*-
"""cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ojlQ3XLurczNC47_RlFaZzKGpS25lYsd
"""

import tensorflow as tf
import os

print(tf.__version__)

IMG_SIZE = (224, 224)
BATCH_SIZE = 32
SHUFFLE_BUFFER = 2000
AUTOTUNE = tf.data.AUTOTUNE

data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.10),
    tf.keras.layers.RandomZoom(0.10),
], name="augmentation")


def relpaths_to_fullpaths(dataset_path, relpaths):
    return [os.path.join(dataset_path, p) for p in relpaths] #returns the abs path of the image

def load_and_preprocess(path, label, augment=False):
    img_bytes = tf.io.read_file(path) #file to a long string of bytes
    img = tf.image.decode_image(img_bytes, channels=3, expand_animations=False) #decode it into a 3d matrix (3 channels)
    img.set_shape([None, None, 3]) # 3d shape

    img = tf.image.resize(img, IMG_SIZE, method=tf.image.ResizeMethod.BILINEAR) #rezising 224 x 224
    # no normalization (pretrained model expects values 0 - 255)

    if augment:
        img = data_augmentation(img, training=True)

    return img, label

def create_dataset(paths,labels,training = False):
    dataset = tf.data.Dataset.from_tensor_slices((paths, labels)) #tensorflow object element example (path,label)
    if training:
        dataset = dataset.shuffle(SHUFFLE_BUFFER,seed = 42 , reshuffle_each_iteration=True) #only for training
        dataset = dataset.map(lambda x, y: load_and_preprocess(x, y, augment=True), num_parallel_calls=AUTOTUNE) #augmentation on
    else :
        dataset = dataset.map(lambda x, y: load_and_preprocess(x, y, augment=False), num_parallel_calls=AUTOTUNE) # aug off
    dataset = dataset.batch(BATCH_SIZE)
    dataset = dataset.prefetch(AUTOTUNE) # optimisation
    return dataset